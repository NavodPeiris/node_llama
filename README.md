### node_llama

this repo uses llamafile.exe to run the gguf models and access it by javascript code.

#### how to setup:

1. git clone repo
2. cd node_llama
3. npm install
4. run command:
```
node index.js
```
this will download the model and start llama.cpp server

#### how to use:

to ask general questions, use generalLlama.js file
```
node generalLlama.js
```

to ask coding related questions, use codeLlama.js file
```
node codeLlama.js
```

### enjoy ðŸ¤–!